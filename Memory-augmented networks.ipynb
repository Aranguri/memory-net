{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the neural net is using the memory for something useful, because when "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to do\n",
    "* benchmark with a number to easily compare between models.\n",
    "* Problem to think: I give you eight real numbers. You have only four slots to store real numbers. How precise can your answer be? Can you recover the full four numbers?\n",
    "* the output of the RNN_{MG} has memory_size. What if it only has size 1. ie, what if we write one memory instead of the whole thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "First we start with a feedforward neural net. But then I realize we need a loop over that fnn - otherwise, we aren't taking into account that the task is sequential.\n",
    "Then, i realize we need a state for the neural net. This happens because the nn receives 0 as input when it's supposed to write. But then, it doesn't know if it's starting to write, or anywhere in the middle\n",
    "Thus, it has to have an state.\n",
    "Now, we have that state. Now I'm testing the nn to see if it learns to use the memory.\n",
    "Indeed, it learned to use the memory. The performance is 5x times better at 800 iterations with memory than without memory.\n",
    "FYI: loss = 0.5 for first 500 iterations. And it takes 1500 iterations to get to 0.02\n",
    "\n",
    "## Copy task\n",
    "The idea of this task is to create a nn that acts as a program that \n",
    "* reads the input, \n",
    "* if we are in the first half: the program writes the input in the memory\n",
    "* if we are in the second half: the program reads from the memory and writes in the output.\n",
    "\n",
    "The difference between a LSTM with memory and a LSTM wo memory is clear when the numbers the LSTM has to remember are more than the dimensionality of its hidden state. \n",
    "\n",
    "## Other task\n",
    "We want to test the model in other task. Which are the capabilities of the agent? It would be nice to have a task that requires a lot of memory, and that we can select the amount of memory as desired. That would be a good environment for a model that doesn't read its whole memory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concepts\n",
    "I think that having a tree structure for the memories is interesting. I think this is the case because even if a learning algorithm has access to the whole input, it could be too big to make a search for every iteration. So, if there is a way to do it in log(n), it would be good. I'm going to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read\n",
    "* Attention and Augmented Recurrent Neural Networks: https://distill.pub/2016/augmented-rnns/\n",
    "* MAC: https://arxiv.org/pdf/1803.03067.pdf\n",
    "* NTM: https://arxiv.org/pdf/1410.5401.pdf\n",
    "* RL-NTM: https://arxiv.org/pdf/1505.00521.pdf\n",
    "* End to end memory networks: https://arxiv.org/pdf/1503.08895.pdf\n",
    "* One-shot learning: https://arxiv.org/pdf/1605.06065v1.pdf\n",
    "* DNC: https://www.nature.com/articles/nature20101.pdf\n",
    "* Neural gpu (NTM that learns to add and multiply) https://arxiv.org/pdf/1511.08228.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
